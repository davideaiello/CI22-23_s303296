{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Aiello Davide\"\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nim Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "        self._steps = 0 \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def is_game_over(self) -> bool:\n",
    "        return not (sum(self._rows) > 0)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "\n",
    "    def give_reward(self):\n",
    "        # if lose give -1 reward\n",
    "        # if not win 0 reward\n",
    "        # if win five +1 reward\n",
    "        if not self:\n",
    "            return 1\n",
    "        if self:     \n",
    "            return 0 \n",
    "        \n",
    "    def possible_moves(self):\n",
    "        return [(r, o) for r, c in enumerate(self._rows) for o in range(1, c + 1) if self._k is None or o <= self._k]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nim-sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm taken from professor's code\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)       # numero di righe maggiori di zero     \n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked\n",
    "\n",
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, states, alpha=0.15, random_factor=0.2):  \n",
    "        self.state_history = []  \n",
    "        self.alpha = alpha\n",
    "        self.random_factor = random_factor\n",
    "        self.G = {}                         \n",
    "        self.init_reward(states)          \n",
    "\n",
    "    def init_reward(self, state):          \n",
    "        for move in state.possible_moves(): \n",
    "                self.G[move] = np.random.uniform(low=0.1, high=1.0) \n",
    "\n",
    "    def choose_action(self, possible_moves):\n",
    "        maxG = -10e15           \n",
    "        next_move = None\n",
    "        randomN = np.random.random()\n",
    "        if randomN < self.random_factor:           \n",
    "            next_move = Nimply(*possible_moves[random.randint(0, len(possible_moves) - 1)])\n",
    "        else:\n",
    "            for move in possible_moves:                                                                                                                              \n",
    "                if self.G[move] >= maxG:   \n",
    "                    next_move = move\n",
    "                    maxG = self.G[move]\n",
    "        return Nimply(*next_move)\n",
    "\n",
    "    def update_state_history(self, move, reward): \n",
    "        self.state_history.append((move, reward))\n",
    "\n",
    "    \n",
    "    def learn(self):\n",
    "        target = 0\n",
    "\n",
    "        for prev, reward in reversed(self.state_history):                        \n",
    "            self.G[prev] = self.G[prev] + self.alpha * (target - self.G[prev])  \n",
    "            target += reward       \n",
    "\n",
    "        self.state_history = []      \n",
    "        self.random_factor -= 10e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.4: reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(state: Nim) -> Nimply: \n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    return Nimply(row, 1)\n",
    "\n",
    "def pure_random(state: Nim) -> Nimply: \n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    if(state.rows[row] > state.k):\n",
    "        num_objects = random.randint(1, state.k)\n",
    "    else:\n",
    "        num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def shortest_row(state: Nim) -> Nimply:\n",
    "    row = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    if(state.rows[row] > k):\n",
    "       num_objects = random.randint(1, k)\n",
    "    else:\n",
    "       num_objects = state.rows[row]\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def Davide_strategy(state: Nim) -> Nimply:\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    if any([True for i in possible_moves if i[1] > 1]):\n",
    "        obj = 0\n",
    "        while(obj == 0):\n",
    "            row_num = random.randint(0, len(state.rows) - 1)\n",
    "            if state.rows[row_num] > 0:\n",
    "                obj = max([i[1] for i in possible_moves if i[0] == row_num], key=lambda i:i)\n",
    "                if obj > k:\n",
    "                    obj = k\n",
    "                ply = Nimply(row_num, obj)\n",
    "    else: \n",
    "        ply = None\n",
    "        while ply == None or ply[1] > k:\n",
    "            ply = Nimply(*possible_moves[random.randint(0, len(possible_moves) - 1)])\n",
    "    return ply\n",
    "\n",
    "def reinforcement_learning(agent, NIM_SIZE, k, NUM_MATCHES): \n",
    "    winrateHistory = []\n",
    "    for i in range(500):   \n",
    "        won = 0             \n",
    "        for m in range(NUM_MATCHES):\n",
    "            nim = Nim(NIM_SIZE, k)\n",
    "            player = 0\n",
    "            while nim:\n",
    "                if player == 0:\n",
    "                    ply0 = Davide_strategy(nim)\n",
    "                    nim.nimming(ply0)\n",
    "                else:\n",
    "                    ply1 = agent.choose_action(nim.possible_moves())\n",
    "                    nim.nimming(ply1)\n",
    "                    agent.update_state_history(ply1, nim.give_reward())\n",
    "\n",
    "\n",
    "                player = 1 - player\n",
    "            winner = 1 - player\n",
    "            if winner == 1:\n",
    "                won += 1\n",
    "            else:\n",
    "                agent.update_state_history(ply1, -1)\n",
    "            agent.learn()\n",
    "        winrateHistory.append(won/NUM_MATCHES*100)\n",
    "    return winrateHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:0: 17.0\n",
      "INFO:root:20: 42.0\n",
      "INFO:root:40: 100.0\n",
      "INFO:root:60: 100.0\n",
      "INFO:root:80: 100.0\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "ALPHA = 0.1\n",
    "RANDOM_FACTOR = 0.4\n",
    "NIM_SIZE = 7\n",
    "k = NIM_SIZE**NIM_SIZE             \n",
    "NUM_MATCHES = 100\n",
    "\n",
    "\n",
    "nim = Nim(NIM_SIZE, k)\n",
    "agent = Agent(nim, alpha=ALPHA, random_factor=RANDOM_FACTOR)      \n",
    "winrateHistory = reinforcement_learning(agent, NIM_SIZE, k, NUM_MATCHES)\n",
    "\n",
    "count = 0\n",
    "for i, wr in enumerate(winrateHistory):\n",
    "    if i % 20 == 0:\n",
    "        logging.info(f\"{i}: {wr}\")\n",
    "        if wr == 100:\n",
    "            count += 1\n",
    "        if count == 3:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffd896555f36165b5062162bf4b32a800e0b4d189bc7405364ec0a2d412e5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
